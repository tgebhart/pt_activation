{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what are the nearest neighbors of the additional graph structure induced by the adversary?\n",
    "\n",
    "- Computing something like an \"average\" subgraph for a class might be difficult because it is unclear how we deal with conflicting directions on edge weights and how we actually average over all the possible subgraphs examples from various classes could elicit\n",
    "    - But this analysis would be fairly interesting. Should think more about how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import parse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import dionysus as dion\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming, cosine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "from pt_activation.models.cff_sigmoid import CFF\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_info(filename):\n",
    "    format_string = 'true-{}_adv-{}_sample-{}.npy'\n",
    "    parsed = parse.parse(format_string, filename)\n",
    "    return {'true class':int(parsed[0]), 'adv class':int(parsed[1]), 'sample':int(parsed[2])}\n",
    "\n",
    "def read_adversaries(loc):\n",
    "    ret = []\n",
    "    for f in os.listdir(loc):\n",
    "        if os.path.isfile(os.path.join(loc,f)) and f.find('.npy') != -1:\n",
    "            adv = np.load(os.path.join(loc, f))\n",
    "            info = get_adv_info(f)\n",
    "            info['adversary'] = adv\n",
    "            ret.append(info)\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_directory_loc = '/home/tgebhart/projects/pt_activation/logdir/adversaries/mnist/projected_gradient_descent/cff_sigmoid.pt'\n",
    "adversaries = read_adversaries(adv_directory_loc)\n",
    "adversaries = sorted(adversaries,  key=lambda k: k['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filtrations(model, batch_size, up_to):\n",
    "    device = torch.device(\"cpu\")\n",
    "    kwargs = {'num_workers': 0, 'pin_memory': False}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "#                            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                       ])), batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    t = 0\n",
    "    res_df = []\n",
    "    nms = []\n",
    "    wms = []\n",
    "    ims = np.empty((up_to, 28*28))\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, hiddens = model(data, hiddens=True)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            for s in range(data.shape[0]):\n",
    "                # check if this makes sense\n",
    "                this_hiddens = [hiddens[0][s], hiddens[1][s], hiddens[2][s]]\n",
    "                print('Filtration: {}'.format(s+t))\n",
    "                f, nm, wm = model.compute_dynamic_filtration2(data[s], this_hiddens, percentile=0, return_nm=True, absolute_value=True)\n",
    "                row = {'filtration':f, 'loss':output.cpu().numpy()[s][0], 'class':target.cpu().numpy()[s], 'prediction':pred.cpu().numpy()[s][0]}\n",
    "                res_df.append(row)\n",
    "                nms.append(nm)\n",
    "                wms.append(wm)\n",
    "                ims[s+t,:] = data[s].numpy().reshape(28*28)\n",
    "\n",
    "            t += batch_size\n",
    "            if t >= up_to:\n",
    "                break\n",
    "\n",
    "    return pd.DataFrame(res_df), nms, wms, ims\n",
    "\n",
    "def create_adversary_filtrations(model, batch_size, up_to, adversaries):\n",
    "    device = torch.device(\"cpu\")\n",
    "    adv_images = torch.tensor(np.array([a['adversary'] for a in adversaries]))\n",
    "    adv_labels = torch.tensor(np.array([a['true class'] for a in adversaries]))\n",
    "    \n",
    "    print(adv_images.shape)\n",
    "    \n",
    "    advs = torch.utils.data.TensorDataset(adv_images, adv_labels)\n",
    "    test_loader = torch.utils.data.DataLoader(advs, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    t = 0\n",
    "    res_df = []\n",
    "    nms = []\n",
    "    wms = []\n",
    "    ims = np.empty((up_to, 28*28))\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, hiddens = model(data, hiddens=True)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            for s in range(data.shape[0]):\n",
    "                # check if this makes sense\n",
    "                this_hiddens = [hiddens[0][s], hiddens[1][s], hiddens[2][s]]\n",
    "                print('Filtration: {}'.format(s+t))\n",
    "                f, nm, wm = model.compute_dynamic_filtration2(data[s], this_hiddens, percentile=0, return_nm=True, absolute_value=True)\n",
    "                row = {'filtration':f, 'loss':output.cpu().numpy()[s][0], 'class':target.cpu().numpy()[s], 'prediction':pred.cpu().numpy()[s][0]}\n",
    "                res_df.append(row)\n",
    "                nms.append(nm)\n",
    "                wms.append(wm)\n",
    "                ims[s+t,:] = data[s].numpy().reshape(28*28)\n",
    "            t += (batch_size)\n",
    "            if t >= up_to:\n",
    "                break\n",
    "\n",
    "    return pd.DataFrame(res_df), nms, wms, ims\n",
    "\n",
    "def get_adv_dist(i,j):\n",
    "    return np.linalg.norm(i-j,2)\n",
    "\n",
    "\n",
    "def create_moved_filtrations(model, ims, labels, devs, times=1, batch_size=10):\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    nims = []\n",
    "    for i in range(len(ims)):\n",
    "#         print('finding alteration number', i)\n",
    "        im = ims[i]\n",
    "        dev = devs[i]\n",
    "        delim = np.zeros(im.shape, dtype=im.dtype)\n",
    "        sigma = 0\n",
    "        while np.linalg.norm(im+delim - im) < dev:\n",
    "            sigma += 0.00001\n",
    "            delim = np.random.normal(scale=sigma, size=im.shape)\n",
    "        nims.append((im+delim).reshape(1,28,28))\n",
    "    tims = torch.FloatTensor(nims)\n",
    "    tlabels = torch.tensor(np.array(labels))\n",
    "    dataset = torch.utils.data.TensorDataset(tims, tlabels)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    t = 0\n",
    "    res_df = []\n",
    "    nms = []\n",
    "    wms = []\n",
    "    new_ims = np.empty((len(ims), 28*28))\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, hiddens = model(data, hiddens=True)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            for s in range(data.shape[0]):\n",
    "                # check if this makes sense\n",
    "                this_hiddens = [hiddens[0][s], hiddens[1][s], hiddens[2][s]]\n",
    "                print('Filtration: {}'.format(s+t))\n",
    "                f, nm, wm = model.compute_dynamic_filtration2(data[s], this_hiddens, percentile=0, return_nm=True, absolute_value=True)\n",
    "                row = {'filtration':f, 'loss':output.cpu().numpy()[s][0], 'class':target.cpu().numpy()[s], 'prediction':pred.cpu().numpy()[s][0]}\n",
    "                res_df.append(row)\n",
    "                nms.append(nm)\n",
    "                wms.append(wm)\n",
    "                new_ims[s+t,:] = data[s].numpy().reshape(28*28)\n",
    "\n",
    "            t += batch_size\n",
    "            \n",
    "    return pd.DataFrame(res_df), nms, wms, new_ims\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = '/home/tgebhart/projects/pt_activation/logdir/models/mnist/cff_sigmoid.pt'\n",
    "model = CFF()\n",
    "model.load_state_dict(torch.load(model_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tgebhart/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtration: 0\n",
      "filtration size 77275\n",
      "Filtration: 1\n",
      "filtration size 142673\n",
      "Filtration: 2\n",
      "filtration size 17357\n",
      "Filtration: 3\n",
      "filtration size 100185\n",
      "Filtration: 4\n",
      "filtration size 59808\n",
      "Filtration: 5\n",
      "filtration size 12070\n",
      "Filtration: 6\n",
      "filtration size 103369\n",
      "Filtration: 7\n",
      "filtration size 86325\n",
      "Filtration: 8\n",
      "filtration size 38112\n",
      "Filtration: 9\n",
      "filtration size 23850\n",
      "Filtration: 10\n",
      "filtration size 126050\n",
      "Filtration: 11\n",
      "filtration size 74575\n",
      "Filtration: 12\n",
      "filtration size 23435\n",
      "Filtration: 13\n",
      "filtration size 74521\n",
      "Filtration: 14\n",
      "filtration size 77261\n",
      "Filtration: 15\n",
      "filtration size 19130\n",
      "Filtration: 16\n",
      "filtration size 36701\n",
      "Filtration: 17\n",
      "filtration size 119416\n",
      "Filtration: 18\n",
      "filtration size 83625\n",
      "Filtration: 19\n",
      "filtration size 30624\n",
      "Filtration: 20\n",
      "filtration size 63195\n",
      "Filtration: 21\n",
      "filtration size 106578\n",
      "Filtration: 22\n",
      "filtration size 117739\n",
      "Filtration: 23\n",
      "filtration size 18964\n",
      "Filtration: 24\n",
      "filtration size 52215\n",
      "Filtration: 25\n",
      "filtration size 131342\n",
      "Filtration: 26\n",
      "filtration size 94605\n",
      "Filtration: 27\n",
      "filtration size 15201\n",
      "Filtration: 28\n",
      "filtration size 116091\n",
      "Filtration: 29\n",
      "filtration size 57034\n",
      "Filtration: 30\n",
      "filtration size 79607\n",
      "Filtration: 31\n",
      "filtration size 67977\n",
      "Filtration: 32\n",
      "filtration size 65927\n",
      "Filtration: 33\n",
      "filtration size 138891\n",
      "Filtration: 34\n",
      "filtration size 79134\n",
      "Filtration: 35\n",
      "filtration size 107699\n",
      "Filtration: 36\n",
      "filtration size 88181\n",
      "Filtration: 37\n",
      "filtration size 47395\n",
      "Filtration: 38\n",
      "filtration size 132961\n",
      "Filtration: 39\n",
      "filtration size 100814\n",
      "Filtration: 40\n",
      "filtration size 17730\n",
      "Filtration: 41\n",
      "filtration size 76976\n",
      "Filtration: 42\n",
      "filtration size 40057\n",
      "Filtration: 43\n",
      "filtration size 67154\n",
      "Filtration: 44\n",
      "filtration size 50711\n",
      "Filtration: 45\n",
      "filtration size 95499\n",
      "Filtration: 46\n",
      "filtration size 91292\n",
      "Filtration: 47\n",
      "filtration size 59052\n",
      "Filtration: 48\n",
      "filtration size 93544\n",
      "Filtration: 49\n",
      "filtration size 125522\n",
      "Filtration: 50\n",
      "filtration size 55471\n",
      "Filtration: 51\n",
      "filtration size 99995\n",
      "Filtration: 52\n",
      "filtration size 74511\n",
      "Filtration: 53\n",
      "filtration size 31964\n",
      "Filtration: 54\n",
      "filtration size 134238\n",
      "Filtration: 55\n",
      "filtration size 85075\n",
      "Filtration: 56\n",
      "filtration size 96164\n",
      "Filtration: 57\n",
      "filtration size 18323\n",
      "Filtration: 58\n",
      "filtration size 21908\n",
      "Filtration: 59\n",
      "filtration size 12794\n",
      "Filtration: 60\n",
      "filtration size 124365\n",
      "Filtration: 61\n",
      "filtration size 59820\n",
      "Filtration: 62\n",
      "filtration size 18574\n",
      "Filtration: 63\n",
      "filtration size 77549\n",
      "Filtration: 64\n",
      "filtration size 83216\n",
      "Filtration: 65\n",
      "filtration size 20813\n",
      "Filtration: 66\n",
      "filtration size 110551\n",
      "Filtration: 67\n",
      "filtration size 39655\n",
      "Filtration: 68\n",
      "filtration size 48714\n",
      "Filtration: 69\n",
      "filtration size 122138\n",
      "Filtration: 70\n",
      "filtration size 97061\n",
      "Filtration: 71\n",
      "filtration size 132567\n",
      "Filtration: 72\n",
      "filtration size 130601\n",
      "Filtration: 73\n",
      "filtration size 30658\n",
      "Filtration: 74\n",
      "filtration size 63287\n",
      "Filtration: 75\n",
      "filtration size 45362\n",
      "Filtration: 76\n",
      "filtration size 94684\n",
      "Filtration: 77\n",
      "filtration size 56631\n",
      "Filtration: 78\n",
      "filtration size 8420\n",
      "Filtration: 79\n",
      "filtration size 44728\n",
      "Filtration: 80\n",
      "filtration size 88427\n",
      "Filtration: 81\n",
      "filtration size 95446\n",
      "Filtration: 82\n",
      "filtration size 131178\n",
      "Filtration: 83\n",
      "filtration size 112469\n",
      "Filtration: 84\n",
      "filtration size 42230\n",
      "Filtration: 85\n",
      "filtration size 118623\n",
      "Filtration: 86\n",
      "filtration size 77796\n",
      "Filtration: 87\n",
      "filtration size 107365\n",
      "Filtration: 88\n",
      "filtration size 132841\n",
      "Filtration: 89\n",
      "filtration size 39035\n",
      "Filtration: 90\n",
      "filtration size 93767\n",
      "Filtration: 91\n",
      "filtration size 121522\n",
      "Filtration: 92\n",
      "filtration size 7690\n",
      "Filtration: 93\n",
      "filtration size 58582\n",
      "Filtration: 94\n",
      "filtration size 120796\n",
      "Filtration: 95\n",
      "filtration size 45907\n",
      "Filtration: 96\n",
      "filtration size 90432\n",
      "Filtration: 97\n",
      "filtration size 12849\n",
      "Filtration: 98\n",
      "filtration size 121582\n",
      "Filtration: 99\n",
      "filtration size 82330\n"
     ]
    }
   ],
   "source": [
    "res_df, nms, wms, ims = create_filtrations(model, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6226, 1, 28, 28])\n",
      "Filtration: 0\n",
      "filtration size 109466\n",
      "Filtration: 1\n",
      "filtration size 143372\n",
      "Filtration: 2\n",
      "filtration size 141785\n",
      "Filtration: 3\n",
      "filtration size 27796\n",
      "Filtration: 4\n",
      "filtration size 95223\n",
      "Filtration: 5\n",
      "filtration size 76950\n",
      "Filtration: 6\n",
      "filtration size 98535\n",
      "Filtration: 7\n",
      "filtration size 58571\n",
      "Filtration: 8\n",
      "filtration size 15921\n",
      "Filtration: 9\n",
      "filtration size 103088\n",
      "Filtration: 10\n",
      "filtration size 73150\n",
      "Filtration: 11\n",
      "filtration size 92115\n",
      "Filtration: 12\n",
      "filtration size 38112\n",
      "Filtration: 13\n",
      "filtration size 14221\n",
      "Filtration: 14\n",
      "filtration size 32709\n",
      "Filtration: 15\n",
      "filtration size 128055\n",
      "Filtration: 16\n",
      "filtration size 119889\n",
      "Filtration: 17\n",
      "filtration size 77703\n",
      "Filtration: 18\n",
      "filtration size 95563\n",
      "Filtration: 19\n",
      "filtration size 8074\n",
      "Filtration: 20\n",
      "filtration size 95070\n",
      "Filtration: 21\n",
      "filtration size 56931\n",
      "Filtration: 22\n",
      "filtration size 57241\n",
      "Filtration: 23\n",
      "filtration size 34304\n",
      "Filtration: 24\n",
      "filtration size 70610\n",
      "Filtration: 25\n",
      "filtration size 72313\n",
      "Filtration: 26\n",
      "filtration size 137089\n",
      "Filtration: 27\n",
      "filtration size 82035\n",
      "Filtration: 28\n",
      "filtration size 43011\n",
      "Filtration: 29\n",
      "filtration size 67862\n",
      "Filtration: 30\n",
      "filtration size 83140\n",
      "Filtration: 31\n",
      "filtration size 115685\n",
      "Filtration: 32\n",
      "filtration size 40885\n",
      "Filtration: 33\n",
      "filtration size 56157\n",
      "Filtration: 34\n",
      "filtration size 75738\n",
      "Filtration: 35\n",
      "filtration size 122882\n",
      "Filtration: 36\n",
      "filtration size 112140\n",
      "Filtration: 37\n",
      "filtration size 70258\n",
      "Filtration: 38\n",
      "filtration size 14844\n",
      "Filtration: 39\n",
      "filtration size 133736\n",
      "Filtration: 40\n",
      "filtration size 116775\n",
      "Filtration: 41\n",
      "filtration size 48760\n",
      "Filtration: 42\n",
      "filtration size 39502\n",
      "Filtration: 43\n",
      "filtration size 73096\n",
      "Filtration: 44\n",
      "filtration size 87599\n",
      "Filtration: 45\n",
      "filtration size 92330\n",
      "Filtration: 46\n",
      "filtration size 78888\n",
      "Filtration: 47\n",
      "filtration size 138891\n",
      "Filtration: 48\n",
      "filtration size 87363\n",
      "Filtration: 49\n",
      "filtration size 59614\n",
      "Filtration: 50\n",
      "filtration size 110192\n",
      "Filtration: 51\n",
      "filtration size 75049\n",
      "Filtration: 52\n",
      "filtration size 46417\n",
      "Filtration: 53\n",
      "filtration size 133182\n",
      "Filtration: 54\n",
      "filtration size 98338\n",
      "Filtration: 55\n",
      "filtration size 19849\n",
      "Filtration: 56\n",
      "filtration size 37315\n",
      "Filtration: 57\n",
      "filtration size 16459\n",
      "Filtration: 58\n",
      "filtration size 99195\n",
      "Filtration: 59\n",
      "filtration size 52884\n",
      "Filtration: 60\n",
      "filtration size 66453\n",
      "Filtration: 61\n",
      "filtration size 69212\n",
      "Filtration: 62\n",
      "filtration size 105608\n",
      "Filtration: 63\n",
      "filtration size 88571\n",
      "Filtration: 64\n",
      "filtration size 80654\n",
      "Filtration: 65\n",
      "filtration size 89731\n",
      "Filtration: 66\n",
      "filtration size 85837\n",
      "Filtration: 67\n",
      "filtration size 133307\n",
      "Filtration: 68\n",
      "filtration size 100677\n",
      "Filtration: 69\n",
      "filtration size 61569\n",
      "Filtration: 70\n",
      "filtration size 68774\n",
      "Filtration: 71\n",
      "filtration size 46260\n",
      "Filtration: 72\n",
      "filtration size 40379\n",
      "Filtration: 73\n",
      "filtration size 136683\n",
      "Filtration: 74\n",
      "filtration size 133327\n",
      "Filtration: 75\n",
      "filtration size 42847\n",
      "Filtration: 76\n",
      "filtration size 97958\n",
      "Filtration: 77\n",
      "filtration size 12859\n",
      "Filtration: 78\n",
      "filtration size 22703\n",
      "Filtration: 79\n",
      "filtration size 19236\n",
      "Filtration: 80\n",
      "filtration size 21041\n",
      "Filtration: 81\n",
      "filtration size 114230\n",
      "Filtration: 82\n",
      "filtration size 66169\n",
      "Filtration: 83\n",
      "filtration size 18574\n",
      "Filtration: 84\n",
      "filtration size 23566\n",
      "Filtration: 85\n",
      "filtration size 81938\n",
      "Filtration: 86\n",
      "filtration size 102952\n",
      "Filtration: 87\n",
      "filtration size 103199\n",
      "Filtration: 88\n",
      "filtration size 21459\n",
      "Filtration: 89\n",
      "filtration size 110551\n",
      "Filtration: 90\n",
      "filtration size 39564\n",
      "Filtration: 91\n",
      "filtration size 83184\n",
      "Filtration: 92\n",
      "filtration size 45773\n",
      "Filtration: 93\n",
      "filtration size 112208\n",
      "Filtration: 94\n",
      "filtration size 129838\n",
      "Filtration: 95\n",
      "filtration size 131494\n",
      "Filtration: 96\n",
      "filtration size 132650\n",
      "Filtration: 97\n",
      "filtration size 124161\n",
      "Filtration: 98\n",
      "filtration size 24495\n",
      "Filtration: 99\n",
      "filtration size 36350\n"
     ]
    }
   ],
   "source": [
    "adv_df, adv_nms, adv_wms, adv_ims = create_adversary_filtrations(model, 50, 100, adversaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.array([get_adv_dist(ims[i], adv_ims[i]) for i in range(res_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtration: 0\n",
      "filtration size 78625\n",
      "Filtration: 1\n",
      "filtration size 143830\n",
      "Filtration: 2\n",
      "filtration size 61146\n",
      "Filtration: 3\n",
      "filtration size 74569\n",
      "Filtration: 4\n",
      "filtration size 29880\n",
      "Filtration: 5\n",
      "filtration size 46446\n",
      "Filtration: 6\n",
      "filtration size 99363\n",
      "Filtration: 7\n",
      "filtration size 69981\n",
      "Filtration: 8\n",
      "filtration size 35446\n",
      "Filtration: 9\n",
      "filtration size 19699\n",
      "Filtration: 10\n",
      "filtration size 116321\n",
      "Filtration: 11\n",
      "filtration size 92271\n",
      "Filtration: 12\n",
      "filtration size 62888\n",
      "Filtration: 13\n",
      "filtration size 38408\n",
      "Filtration: 14\n",
      "filtration size 90954\n",
      "Filtration: 15\n",
      "filtration size 40900\n",
      "Filtration: 16\n",
      "filtration size 76917\n",
      "Filtration: 17\n",
      "filtration size 127778\n",
      "Filtration: 18\n",
      "filtration size 55306\n",
      "Filtration: 19\n",
      "filtration size 31194\n",
      "Filtration: 20\n",
      "filtration size 38058\n",
      "Filtration: 21\n",
      "filtration size 80489\n",
      "Filtration: 22\n",
      "filtration size 101068\n",
      "Filtration: 23\n",
      "filtration size 75654\n",
      "Filtration: 24\n",
      "filtration size 40440\n",
      "Filtration: 25\n",
      "filtration size 133692\n",
      "Filtration: 26\n",
      "filtration size 110721\n",
      "Filtration: 27\n",
      "filtration size 18461\n",
      "Filtration: 28\n",
      "filtration size 133779\n",
      "Filtration: 29\n",
      "filtration size 16934\n",
      "Filtration: 30\n",
      "filtration size 63423\n",
      "Filtration: 31\n",
      "filtration size 21246\n",
      "Filtration: 32\n",
      "filtration size 90035\n",
      "Filtration: 33\n",
      "filtration size 140426\n",
      "Filtration: 34\n",
      "filtration size 93340\n",
      "Filtration: 35\n",
      "filtration size 112195\n",
      "Filtration: 36\n",
      "filtration size 53006\n",
      "Filtration: 37\n",
      "filtration size 27939\n",
      "Filtration: 38\n",
      "filtration size 106677\n",
      "Filtration: 39\n",
      "filtration size 120863\n",
      "Filtration: 40\n",
      "filtration size 85423\n",
      "Filtration: 41\n",
      "filtration size 64131\n",
      "Filtration: 42\n",
      "filtration size 80180\n",
      "Filtration: 43\n",
      "filtration size 23842\n",
      "Filtration: 44\n",
      "filtration size 97110\n",
      "Filtration: 45\n",
      "filtration size 76601\n",
      "Filtration: 46\n",
      "filtration size 102961\n",
      "Filtration: 47\n",
      "filtration size 80888\n",
      "Filtration: 48\n",
      "filtration size 111677\n",
      "Filtration: 49\n",
      "filtration size 137379\n",
      "Filtration: 50\n",
      "filtration size 96786\n",
      "Filtration: 51\n",
      "filtration size 64456\n",
      "Filtration: 52\n",
      "filtration size 17100\n",
      "Filtration: 53\n",
      "filtration size 36885\n",
      "Filtration: 54\n",
      "filtration size 131315\n",
      "Filtration: 55\n",
      "filtration size 42980\n",
      "Filtration: 56\n",
      "filtration size 96537\n",
      "Filtration: 57\n",
      "filtration size 26349\n",
      "Filtration: 58\n",
      "filtration size 31383\n",
      "Filtration: 59\n",
      "filtration size 25768\n",
      "Filtration: 60\n",
      "filtration size 105495\n",
      "Filtration: 61\n",
      "filtration size 29146\n",
      "Filtration: 62\n",
      "filtration size 24089\n",
      "Filtration: 63\n",
      "filtration size 22552\n",
      "Filtration: 64\n",
      "filtration size 92387\n",
      "Filtration: 65\n",
      "filtration size 37758\n",
      "Filtration: 66\n",
      "filtration size 110413\n",
      "Filtration: 67\n",
      "filtration size 37633\n",
      "Filtration: 68\n",
      "filtration size 63451\n",
      "Filtration: 69\n",
      "filtration size 117519\n",
      "Filtration: 70\n",
      "filtration size 83203\n",
      "Filtration: 71\n",
      "filtration size 132658\n",
      "Filtration: 72\n",
      "filtration size 127799\n",
      "Filtration: 73\n",
      "filtration size 15871\n",
      "Filtration: 74\n",
      "filtration size 17810\n",
      "Filtration: 75\n",
      "filtration size 69942\n",
      "Filtration: 76\n",
      "filtration size 127842\n",
      "Filtration: 77\n",
      "filtration size 91293\n",
      "Filtration: 78\n",
      "filtration size 28584\n",
      "Filtration: 79\n",
      "filtration size 60005\n",
      "Filtration: 80\n",
      "filtration size 79207\n",
      "Filtration: 81\n",
      "filtration size 93098\n",
      "Filtration: 82\n",
      "filtration size 122991\n",
      "Filtration: 83\n",
      "filtration size 90117\n",
      "Filtration: 84\n",
      "filtration size 22362\n",
      "Filtration: 85\n",
      "filtration size 99069\n",
      "Filtration: 86\n",
      "filtration size 80809\n",
      "Filtration: 87\n",
      "filtration size 92793\n",
      "Filtration: 88\n",
      "filtration size 129604\n",
      "Filtration: 89\n",
      "filtration size 22106\n",
      "Filtration: 90\n",
      "filtration size 109372\n",
      "Filtration: 91\n",
      "filtration size 47211\n",
      "Filtration: 92\n",
      "filtration size 19850\n",
      "Filtration: 93\n",
      "filtration size 65313\n",
      "Filtration: 94\n",
      "filtration size 134508\n",
      "Filtration: 95\n",
      "filtration size 100173\n",
      "Filtration: 96\n",
      "filtration size 102021\n",
      "Filtration: 97\n",
      "filtration size 27111\n",
      "Filtration: 98\n",
      "filtration size 101510\n",
      "Filtration: 99\n",
      "filtration size 99298\n"
     ]
    }
   ],
   "source": [
    "moved_df, moved_nms, moved_wms, moved_ims = create_moved_filtrations(model, ims, res_df['class'], dists, times=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversary Accuracy: 0.0\n",
      "Moved Accuracy: 0.8987341772151899\n",
      "Actual Accuracy: 0.9620253164556962\n"
     ]
    }
   ],
   "source": [
    "res_df = res_df[adv_df['prediction'] != adv_df['class']]\n",
    "moved_df = moved_df[adv_df['prediction'] != adv_df['class']]\n",
    "adv_df = adv_df[adv_df['prediction'] != adv_df['class']]\n",
    "\n",
    "print('Adversary Accuracy:', adv_df[adv_df['prediction'] == adv_df['class']].shape[0]/adv_df.shape[0])\n",
    "print('Moved Accuracy:', moved_df[moved_df['prediction'] == moved_df['class']].shape[0]/moved_df.shape[0])\n",
    "print('Actual Accuracy:', res_df[res_df['prediction'] == res_df['class']].shape[0]/res_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df[adv_df['prediction'] != adv_df['class']]\n",
    "moved_df = moved_df[adv_df['prediction'] != adv_df['class']]\n",
    "adv_df = adv_df[adv_df['prediction'] != adv_df['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>filtration</th>\n",
       "      <th>loss</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[(4144), (4202), (4144, 4202), (429), (352), (...</td>\n",
       "      <td>-8.079764</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[(4634), (4691), (4634, 4691), (4587), (4693),...</td>\n",
       "      <td>-4.600676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[(4599), (4811), (4599, 4811), (4359), (4813),...</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[(464), (465), (482), (555), (556), (630), (63...</td>\n",
       "      <td>-7.923281</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>[(503), (474), (495), (515), (563), (568), (58...</td>\n",
       "      <td>-10.021047</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                         filtration       loss  \\\n",
       "0      7  [(4144), (4202), (4144, 4202), (429), (352), (...  -8.079764   \n",
       "1      2  [(4634), (4691), (4634, 4691), (4587), (4693),...  -4.600676   \n",
       "3      0  [(4599), (4811), (4599, 4811), (4359), (4813),...  -0.008552   \n",
       "4      4  [(464), (465), (482), (555), (556), (630), (63...  -7.923281   \n",
       "6      4  [(503), (474), (495), (515), (563), (568), (58... -10.021047   \n",
       "\n",
       "   prediction  \n",
       "0           7  \n",
       "1           2  \n",
       "3           0  \n",
       "4           4  \n",
       "6           4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [{v: k for k, v in nm.items()} for nm in nms]\n",
    "adv_ids = [{v: k for k, v in nm.items()} for nm in adv_nms]\n",
    "moved_ids = [{v: k for k, v in nm.items()} for nm in moved_nms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_sample_graphs(res_df, ids, wms):\n",
    "    sample_graphs = []\n",
    "    dgms = []\n",
    "    lifetimes = []\n",
    "    for s in range(res_df.shape[0]):\n",
    "        print(s)\n",
    "        wm = wms[s]\n",
    "        tnms = ids[s]\n",
    "        subgraphs = {}\n",
    "        f = res_df['filtration'].iloc[s]\n",
    "        m = dion.homology_persistence(f)\n",
    "        dgm = dion.init_diagrams(m,f)[0]\n",
    "        dgms.append(dgm)\n",
    "        for i,c in enumerate(m):\n",
    "            if len(c) == 2:\n",
    "                w = f[i].data\n",
    "                if (tnms[f[c[0].index][0]],tnms[f[c[1].index][0]]) in wm:\n",
    "                    w = wm[(tnms[f[c[0].index][0]],tnms[f[c[1].index][0]])]\n",
    "                elif (tnms[f[c[1].index][0]],tnms[f[c[0].index][0]]) in wm:\n",
    "                    w = wm[(tnms[f[c[1].index][0]],tnms[f[c[0].index][0]])]\n",
    "#                 else:\n",
    "#                     print((tnms[f[c[0].index][0]],tnms[f[c[1].index][0]]))\n",
    "#                     raise Exception('NO WM!')\n",
    "                if False: #tnms[f[c[0].index][0]] in subgraphs:\n",
    "                    subgraphs[tnms[f[c[0].index][0]]].add_edge(tnms[f[c[0].index][0]],tnms[f[c[1].index][0]], weight=w)\n",
    "                else:\n",
    "                    eaten = False\n",
    "                    for k, v in subgraphs.items():\n",
    "                        if v.has_node(tnms[f[c[0].index][0]]):\n",
    "                            if tnms[f[c[1].index][0]] in subgraphs:\n",
    "                                v.add_node(f[c[1].index][0])\n",
    "#                                 subgraphs[k] = nx.union(v, subgraphs[tnms[f[c[1].index][0]]])\n",
    "                            else:\n",
    "                                v.add_edge(tnms[f[c[0].index][0]], tnms[f[c[1].index][0]], weight=w)\n",
    "                            eaten = True\n",
    "                            break\n",
    "                    if not eaten:\n",
    "                        g = nx.Graph()\n",
    "                        g.add_edge(tnms[f[c[0].index][0]], tnms[f[c[1].index][0]], weight=w)\n",
    "                        subgraphs[tnms[f[c[0].index][0]]] = g\n",
    "                        \n",
    "        sample_graphs.append(subgraphs)\n",
    "        lifetimes.append(create_lifetimes(f, subgraphs,dgm,ids[s]))\n",
    "    return sample_graphs, dgms, lifetimes\n",
    "\n",
    "def create_lifetimes(f, subgraphs, dgm, ids):\n",
    "    lifetimes = {}\n",
    "    for pt in dgm:\n",
    "        k = ids[f[pt.data][0]] \n",
    "        if k in subgraphs.keys():\n",
    "            if pt.death < float('inf'):\n",
    "                lifetimes[k] = pt.birth - pt.death\n",
    "            else:\n",
    "                lifetimes[k] = pt.birth\n",
    "    return lifetimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4599",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-94594d316958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifetimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sample_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-29e432e14941>\u001b[0m in \u001b[0;36mcreate_sample_graphs\u001b[0;34m(res_df, ids, wms)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtnms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtnms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtnms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtnms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtnms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtnms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4599"
     ]
    }
   ],
   "source": [
    "sample_graphs, dgms, lifetimes = create_sample_graphs(res_df, ids, wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv_sample_graphs, adv_dgms, adv_lifetimes = create_sample_graphs(adv_df, adv_ids, adv_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moved_sample_graphs, moved_dgms, moved_lifetimes = create_sample_graphs(moved_df, moved_ids, moved_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goi = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131).imshow(ims[goi].reshape(28,28), cmap='gray')\n",
    "plt.subplot(132).imshow(adv_ims[goi].reshape(28,28), cmap='gray')\n",
    "plt.subplot(133).imshow(moved_ims[goi].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dion.plot.plot_diagram(dgms[goi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dion.plot.plot_diagram(adv_dgms[goi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dion.plot.plot_diagram(moved_dgms[goi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifetimes[goi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_lifetimes[goi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_lifetimes[goi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgk = (2,0,37)\n",
    "agk = (2,0,37)\n",
    "mgk = sgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'node_color': 'red',\n",
    "    'node_size': 2,\n",
    "    'width': 2,\n",
    "    'with_labels':True}\n",
    "nx.draw_spring(sample_graphs[goi][sgk], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'node_color': 'red',\n",
    "    'node_size': 2,\n",
    "    'width': 2,\n",
    "    'with_labels':True}\n",
    "nx.draw_spring(adv_sample_graphs[goi][agk], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'node_color': 'red',\n",
    "    'node_size': 2,\n",
    "    'width': 2,\n",
    "    'with_labels':True}\n",
    "nx.draw_spring(moved_sample_graphs[goi][mgk], **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(g1, g2, ret_labels=False):\n",
    "    nodeset = set(list(g1.nodes) + list(g2.nodes))\n",
    "    g1_vec = np.zeros((len(nodeset)))\n",
    "    g2_vec = np.zeros((len(nodeset)))\n",
    "    nodesetlist = list(nodeset)\n",
    "    for i in range(len(nodesetlist)):\n",
    "        node = nodesetlist[i]\n",
    "        if node in g1.nodes:\n",
    "            g1_vec[i] = 1.0\n",
    "        if node in g2.nodes:\n",
    "            g2_vec[i] = 1.0\n",
    "    if ret_labels:\n",
    "        return hamming(g1_vec, g2_vec), nodesetlist\n",
    "    else:\n",
    "        return hamming(g1_vec, g2_vec)\n",
    "    \n",
    "def edge_hamming_distance(g1, g2, ret_labels=False):\n",
    "    edgeset = set(list(g1.edges) + list(g2.edges))\n",
    "    g1_vec = np.zeros((len(edgeset)))\n",
    "    g2_vec = np.zeros((len(edgeset)))\n",
    "    edgesetlist = list(edgeset)\n",
    "    for i in range(len(edgesetlist)):\n",
    "        edge = edgesetlist[i]\n",
    "        if edge in g1.edges:\n",
    "            g1_vec[i] = 1.0\n",
    "        if edge in g2.edges:\n",
    "            g2_vec[i] = 1.0\n",
    "    if ret_labels:\n",
    "        return hamming(g1_vec, g2_vec), edgesetlist\n",
    "    else:\n",
    "        return hamming(g1_vec, g2_vec)\n",
    "    \n",
    "def lifetime_weighted_edge_distance(subgraphs1,subgraphs2,lifetimes1,lifetimes2,ret_labels=False):\n",
    "    edges1 = {}\n",
    "    edges2 = {}\n",
    "    sg1keys = list(subgraphs1.keys())\n",
    "    sg2keys = list(subgraphs2.keys())\n",
    "    lifetimes1 = list(lifetimes1.values())\n",
    "    lifetimes2 = list(lifetimes2.values())\n",
    "    ml1 = max(lifetimes1)\n",
    "    ml2 = max(lifetimes2)\n",
    "    for i in range(len(sg1keys)):\n",
    "        g = subgraphs1[sg1keys[i]]\n",
    "        for e in g.edges:\n",
    "            edges1[e] = lifetimes1[i]/ml1\n",
    "    for i in range(len(sg2keys)):\n",
    "        g = subgraphs2[sg2keys[i]]\n",
    "        for e in g.edges:\n",
    "            edges2[e] = lifetimes2[i]/ml2\n",
    "    edgeset = set(list(edges1.keys()) + list(edges2.keys()))\n",
    "    g1_vec = np.zeros((len(edgeset)))\n",
    "    g2_vec = np.zeros((len(edgeset)))\n",
    "    edgesetlist = list(edgeset)\n",
    "    for i in range(len(edgesetlist)):\n",
    "        edge = edgesetlist[i]\n",
    "        if edge in edges1:\n",
    "            g1_vec[i] += edges1[edge]\n",
    "        if edge in edges2:\n",
    "            g2_vec[i] += edges2[edge]\n",
    "    if ret_labels:\n",
    "        return cosine(g1_vec, g2_vec), edgesetlist\n",
    "    else:\n",
    "        return cosine(g1_vec, g2_vec)\n",
    "    \n",
    "def weighted_edge_distance(g1, g2, ret_labels=False):\n",
    "    edgeset = set(list(g1.edges) + list(g2.edges))\n",
    "    g1_vec = np.zeros((len(edgeset)))\n",
    "    g2_vec = np.zeros((len(edgeset)))\n",
    "    edgesetlist = list(edgeset)\n",
    "    for i in range(len(edgesetlist)):\n",
    "        edge = edgesetlist[i]\n",
    "        if edge in g1.edges:\n",
    "            g1_vec[i] = g1[edge[0]][edge[1]]['weight']\n",
    "        if edge in g2.edges:\n",
    "            g2_vec[i] = g2[edge[0]][edge[1]]['weight']\n",
    "    if ret_labels:\n",
    "        return cosine(g1_vec, g2_vec), edgesetlist\n",
    "    else:\n",
    "        return cosine(g1_vec, g2_vec)\n",
    "    \n",
    "def total_edge_weights(graphs):\n",
    "    emap = {}\n",
    "    for g in graphs:\n",
    "        for e in g.edges:\n",
    "            if e in emap:\n",
    "                emap[e] += g[e[0]][e[1]]['weight']\n",
    "            else:\n",
    "                emap[e] = g[e[0]][e[1]]['weight']\n",
    "    return emap\n",
    "\n",
    "def count_nodes(graphs):\n",
    "    nmap = {}\n",
    "    for g in graphs:\n",
    "        for n in g.nodes:\n",
    "            if n in nmap:\n",
    "                nmap[n] += 1.0\n",
    "            else:\n",
    "                nm[2] = 1.0\n",
    "    return nmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-weighted_edge_distance(sample_graphs[goi][sgk], adv_sample_graphs[goi][agk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-weighted_edge_distance(sample_graphs[goi][sgk], moved_sample_graphs[goi][mgk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_res_df = res_df.sort_values(by=['prediction'])\n",
    "sorted_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_sim_mat = np.zeros((len(combs),len(adv_combs)))\n",
    "# for i in range(len(combs)):\n",
    "#     g = combs[i]\n",
    "#     for j in range(len(adv_combs)):\n",
    "#         ag = adv_combs[j]\n",
    "#         comb_sim_mat[i,j] = 1 - weighted_edge_distance(g,ag)\n",
    "\n",
    "# comb_sim_mat = np.zeros((len(sample_graphs), len(adv_sample_graphs)))\n",
    "# for i in range(len(sample_graphs)):\n",
    "#     for j in range(len(adv_sample_graphs)):\n",
    "#         comb_sim_mat[i,j] = 1 - lifetime_weighted_edge_distance(sample_graphs[i],adv_sample_graphs[j],lifetimes[i],adv_lifetimes[j])\n",
    "\n",
    "adv_sim_mat = np.zeros((len(sample_graphs), len(adv_sample_graphs)))\n",
    "for i in range(len(sample_graphs)):\n",
    "    for j in range(len(adv_sample_graphs)):\n",
    "        adv_sim_mat[i,j] = 1 - lifetime_weighted_edge_distance(sample_graphs[i],adv_sample_graphs[j],lifetimes[i],adv_lifetimes[j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(adv_sim_mat, xticklabels=5, yticklabels=5)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tick_params(axis='y',labelsize=5)\n",
    "plt.tick_params(axis='x',labelsize=5)\n",
    "plt.ylabel('Unaltered Subgraphs')\n",
    "plt.xlabel('Adversarial Subgraphs')\n",
    "plt.savefig('/home/tgebhart/projects/pt_activation/logdir/vis/cff_mnist/adv_comb_heatmap_sigmoid.png', format='png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_sim_mat = np.zeros((len(sample_graphs), len(moved_sample_graphs)))\n",
    "for i in range(len(sample_graphs)):\n",
    "    for j in range(len(moved_sample_graphs)):\n",
    "        moved_sim_mat[i,j] = 1 - lifetime_weighted_edge_distance(sample_graphs[i],moved_sample_graphs[j],lifetimes[i],moved_lifetimes[j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(moved_sim_mat, xticklabels=5, yticklabels=5)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tick_params(axis='y',labelsize=5)\n",
    "plt.tick_params(axis='x',labelsize=5)\n",
    "plt.ylabel('Unaltered Subgraphs')\n",
    "plt.xlabel('Adversarial Subgraphs')\n",
    "plt.savefig('/home/tgebhart/projects/pt_activation/logdir/vis/cff_mnist/moved_comb_heatmap_sigmoid.png', format='png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_dists = np.array([get_adv_dist(ims[i], moved_ims[i]) for i in range(res_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(np.diagonal(adv_sim_mat), bins, alpha=0.5, label='Adversaries', color='r')\n",
    "plt.hist(np.diagonal(moved_sim_mat), bins, alpha=0.5, label='Randomly Perturbed', color='b')\n",
    "plt.xlabel('Similarity to Unaltered Subgraph')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(dists, bins, alpha=0.5, label='Adversaries', color='r')\n",
    "plt.hist(moved_dists, bins, alpha=0.5, label='Random Pertubation', color='b')\n",
    "plt.xlabel('Distance to Unaltered Image')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_generators(g):\n",
    "    return len(g)\n",
    "def compute_num_edges(g):\n",
    "    num_edges = 0\n",
    "    for sgk in g:\n",
    "        num_edges += len(g[sgk].edges())\n",
    "    return num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generators = [compute_num_generators(g) for g in sample_graphs]\n",
    "adv_num_generators = [compute_num_generators(g) for g in adv_sample_graphs]\n",
    "moved_num_generators = [compute_num_generators(g) for g in moved_sample_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(num_generators, bins, alpha=0.5, label='Unaltered', color='g')\n",
    "plt.hist(adv_num_generators, bins, alpha=0.5, label='Adversaries', color='r')\n",
    "plt.hist(moved_num_generators, bins, alpha=0.5, label='Random Pertubation', color='b')\n",
    "plt.xlabel('Number of Generators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edges = [compute_num_edges(g) for g in sample_graphs]\n",
    "adv_num_edges = [compute_num_edges(g) for g in adv_sample_graphs]\n",
    "moved_num_edges = [compute_num_edges(g) for g in moved_sample_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 25\n",
    "plt.hist(num_edges, bins, alpha=0.5, label='Unaltered', color='g')\n",
    "plt.hist(adv_num_edges, bins, alpha=0.5, label='Adversaries', color='r')\n",
    "plt.hist(moved_num_edges, bins, alpha=0.5, label='Random Pertubation', color='b')\n",
    "plt.xlabel('Number of Edges')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the set differences for each adversary and compare these set differences to each of the unaltered images like we did for the adv_sim_mat above. \n",
    "- Sort this similarity matrix by the _predicted_ class of the adversary. We would expect to see some sort of relationship emerge if these subgraphs were targeting class-specific information within the persistent subgraphs\n",
    "- Compute these differences based on the composed graphs like in `lifetime_weighted_edge_distance()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_difference(subgraphs1, subgraphs2):\n",
    "    sg1keys = list(subgraphs1.keys())\n",
    "    sg2keys = list(subgraphs2.keys())\n",
    "    remove_edges = []\n",
    "    edges2 = []\n",
    "    for i in range(len(sg1keys)):\n",
    "        g = subgraphs1[sg1keys[i]]\n",
    "        remove_edges += list(g.edges)\n",
    "    for i in range(len(sg2keys)):\n",
    "        g = subgraphs2[sg2keys[i]]\n",
    "        edges2 += list(g.edges)\n",
    "    keep_edges = set(edges2).difference(set(remove_edges))\n",
    "    ret_graph = nx.compose_all([subgraphs2[k] for k in sg2keys])\n",
    "    rge = list(ret_graph.edges())\n",
    "    ret_graph.remove_edges_from(e for e in rge if e not in keep_edges)\n",
    "    return ret_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_res_df = res_df.sort_values(by=['prediction'])\n",
    "sorted_adv_df = adv_df.sort_values(by=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_adv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_differences = [set_difference(sample_graphs[i], adv_sample_graphs[i]) for i in range(len(sample_graphs))]\n",
    "\n",
    "combs = []\n",
    "for i in range(len(sample_graphs)):\n",
    "    combs.append(nx.compose_all([sample_graphs[i][k] for k in sample_graphs[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_sim_mat = np.zeros((len(combs),len(adv_differences)))\n",
    "for i in range(len(combs)):\n",
    "    g = combs[i]\n",
    "    for j in range(len(adv_differences)):\n",
    "        ag = adv_differences[j]\n",
    "        diff_sim_mat[i,j] = 1 - weighted_edge_distance(g,ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_diff_sim_mat = np.empty(diff_sim_mat.shape)\n",
    "sidxs = list(sorted_res_df.index)\n",
    "aidxs = list(sorted_adv_df.index)\n",
    "aidxs = sidxs\n",
    "for i in range(len(sidxs)):\n",
    "    for j in range(len(aidxs)):\n",
    "        sorted_diff_sim_mat[i,j] = diff_sim_mat[sidxs[i],aidxs[j]]\n",
    "        \n",
    "sdsmdf = pd.DataFrame(sorted_diff_sim_mat, columns=sorted_adv_df['prediction'], index=sorted_res_df['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(sorted_diff_sim_mat, xticklabels=5, yticklabels=5)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tick_params(axis='y',labelsize=5)\n",
    "plt.tick_params(axis='x',labelsize=5)\n",
    "plt.ylabel('Unaltered Subgraphs')\n",
    "plt.xlabel('Adversarial Subgraphs')\n",
    "plt.savefig('/home/tgebhart/projects/pt_activation/logdir/vis/cff_mnist/adv_diff_heatmap_sigmoid.png', format='png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
